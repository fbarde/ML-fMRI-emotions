{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90f3e6af",
   "metadata": {},
   "source": [
    "# General aim of the notebook\n",
    "\n",
    "This notebook implements the different machine learning methods tested for the classification of the emotions. The parameters of the models have already been optimized, their optimization process can be found in other notebooks.\n",
    "\n",
    "The notebook trains and tests the models.\n",
    "\n",
    "# How to use this notebook\n",
    "\n",
    "1. Change the datapath and load the data\n",
    "\n",
    "\n",
    "2. Run the preprocessing\n",
    "\n",
    "\n",
    "3. Train one of the models, skip the others\n",
    "\n",
    "\n",
    "4. Run the two cells of the section Analysis of Prediction, they will return a table with precision per emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa634043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74824413",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed59375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------data paths------------------------------------------------------------------------------------------\n",
    "data_train_path = 'C:/Users/manon/Desktop/Projet_2 _ML/code/datas/Split_48_neutre/Combined_All_Train_80.csv'\n",
    "data_test_path = 'C:/Users/manon/Desktop/Projet_2 _ML/code/datas/Split_48_neutre/Combined_All_Test_80.csv'\n",
    "\n",
    "#--------loading the data and spliting between features and predictions--------------------------------------\n",
    "tx_train = pd.read_csv(data_train_path,sep=\",\",squeeze=True)\n",
    "X_train=tx_train.iloc[:, :48]\n",
    "ytr = pd.read_csv(data_train_path,sep=\",\",usecols=[48],squeeze=True)\n",
    "\n",
    "tx_test = pd.read_csv(data_test_path,sep=\",\",squeeze=True)\n",
    "X_test=tx_test.iloc[:, :48]\n",
    "yte = pd.read_csv(data_test_path,sep=\",\",usecols=[48],squeeze=True)\n",
    "\n",
    "#---------Adding features name (i.e. number of the brain region represented by the feature)------------------\n",
    "def add_column_names(data):\n",
    "    \n",
    "    liste=[]\n",
    "    for i in range(48):\n",
    "        liste.append(str(i+1))\n",
    "    data.columns=liste\n",
    "    return data,liste\n",
    "\n",
    "X_train,liste = add_column_names(X_train)\n",
    "X_test,liste = add_column_names(X_test)\n",
    "\n",
    "#---------Convert y to int to be compatible with future prediction--------------------------------------------\n",
    "ytr = ytr.astype(np.int64)\n",
    "yte = yte.astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc4fe63",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "###  1. Data standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e8ab8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    \"\"\"Standardize the original data set.\"\"\"\n",
    "    mean_x = np.mean(x)\n",
    "    x = x - mean_x\n",
    "    std_x = np.std(x)\n",
    "    x = x / std_x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf3e9b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain=standardize(X_train)\n",
    "X_test=standardize(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5e4584",
   "metadata": {},
   "source": [
    "# Training\n",
    "### 1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b6a8828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.330603889457523\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators = 500, criterion = 'gini', max_depth=9,random_state = 42)\n",
    "classifier.fit(X_train, ytr)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(yte, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356e8cfb",
   "metadata": {},
   "source": [
    "### 2. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0bac5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.283179802115319\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree_model = DecisionTreeClassifier(max_depth = 4, criterion='gini').fit(X_train, ytr)\n",
    "Y_pred = dtree_model.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(yte, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5413e710",
   "metadata": {},
   "source": [
    "### 3. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f9be8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2811327192084613\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 0.025).fit(X_train, ytr) #c=0.02 for linear,0.33 for poly, 0.01 for sigmoid\n",
    "Y_pred = svm_model_linear.predict(X_test)\n",
    "accuracy = svm_model_linear.score(X_test, yte)\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e659a0",
   "metadata": {},
   "source": [
    "### 4. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8b8c96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2739679290344592\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 873, weights='distance').fit(X_train, ytr)\n",
    "Y_pred = knn.predict(X_test)\n",
    "accuracy = knn.score(X_test, yte)\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cae675",
   "metadata": {},
   "source": [
    "### 5. Convolutional NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcec2275",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1=tf.expand_dims(X_train, axis=-1)\n",
    "X_test1=tf.expand_dims(X_test, axis=-1)\n",
    "y_train1 = tf.keras.utils.to_categorical(ytr,num_classes=14)\n",
    "y_test1 = tf.keras.utils.to_categorical(yte,num_classes=14)\n",
    "\n",
    "n_samples, n_features = X_train1.shape[0], X_train1.shape[1]\n",
    "n_outputs=14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a64b72be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, Dropout, MaxPooling1D, Flatten, Dense\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Conv1D(filters=12, kernel_size=5, activation='tanh',kernel_initializer='he_uniform',input_shape=(n_features, 1)))\n",
    "model.add(Conv1D(filters=64, kernel_size=5, activation='tanh',kernel_initializer='he_uniform'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(60, input_dim=199, activation='tanh'))\n",
    "model.add(Dense(14, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "optimizer = tf.keras.optimizers.Nadam(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "478ca7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy, model):\n",
    "    epochs, batch_size = 10, 1\n",
    "    n_samples, n_features = X_train.shape[0], X_train.shape[1]\n",
    "    n_outputs=14\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2afe4142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8910/8910 [==============================] - 14s 2ms/step - loss: 0.2225 - accuracy: 0.2615\n",
      "Epoch 2/10\n",
      "8910/8910 [==============================] - 14s 2ms/step - loss: 0.1990 - accuracy: 0.3506\n",
      "Epoch 3/10\n",
      "8910/8910 [==============================] - 13s 1ms/step - loss: 0.1829 - accuracy: 0.4253\n",
      "Epoch 4/10\n",
      "8910/8910 [==============================] - 13s 1ms/step - loss: 0.1726 - accuracy: 0.4694\n",
      "Epoch 5/10\n",
      "8910/8910 [==============================] - 13s 1ms/step - loss: 0.1647 - accuracy: 0.5067\n",
      "Epoch 6/10\n",
      "8910/8910 [==============================] - 13s 1ms/step - loss: 0.1594 - accuracy: 0.5265\n",
      "Epoch 7/10\n",
      "8910/8910 [==============================] - 13s 1ms/step - loss: 0.1530 - accuracy: 0.5438\n",
      "Epoch 8/10\n",
      "8910/8910 [==============================] - 13s 1ms/step - loss: 0.1484 - accuracy: 0.5651\n",
      "Epoch 9/10\n",
      "8910/8910 [==============================] - 14s 2ms/step - loss: 0.1459 - accuracy: 0.5773\n",
      "Epoch 10/10\n",
      "8910/8910 [==============================] - 13s 1ms/step - loss: 0.1447 - accuracy: 0.5842\n",
      "2931/2931 [==============================] - 2s 804us/step - loss: 0.2704 - accuracy: 0.27872s - loss: 0.2697 - accuracy: 0. - ETA: 2s - loss: 0.2739 - accuracy: 0. - ETA:  - ETA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2787444591522217"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(X_train1, y_train1, X_test1, y_test1, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9611dbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "Y_pred = np.argmax(Y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8be7da3",
   "metadata": {},
   "source": [
    "### 6. Fully Connected NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "69dc4b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2=tf.expand_dims(X_train, axis=-1)\n",
    "X_test2=tf.expand_dims(X_test, axis=-1)\n",
    "y_train2 = tf.keras.utils.to_categorical(ytr,num_classes=14)\n",
    "y_test2 = tf.keras.utils.to_categorical(yte,num_classes=14)\n",
    "\n",
    "n_samples, n_features = X_train2.shape[0], X_train2.shape[1]\n",
    "n_outputs=14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "16701cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manon\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adagrad.py:74: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adagrad, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, Dropout, MaxPooling1D, Flatten, Dense\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Dense(6, input_dim=48, activation='relu',kernel_initializer='zero'))\n",
    "model.add(Dense(14, activation='softmax'))\n",
    "    \n",
    "# Compile model\n",
    "optimizer = tf.keras.optimizers.Adagrad(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1426371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy, model):\n",
    "    epochs, batch_size = 10, 100\n",
    "    n_samples, n_features = X_train.shape[0], X_train.shape[1]\n",
    "    n_outputs=14\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "124d1da2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 2.6360 - accuracy: 0.2345\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 0s 998us/step - loss: 2.6320 - accuracy: 0.2371\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 2.6293 - accuracy: 0.2371\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 2.6270 - accuracy: 0.2371\n",
      "Epoch 5/10\n",
      "90/90 [==============================] - 0s 991us/step - loss: 2.6251 - accuracy: 0.2371\n",
      "Epoch 6/10\n",
      "90/90 [==============================] - 0s 979us/step - loss: 2.6233 - accuracy: 0.2371\n",
      "Epoch 7/10\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 2.6217 - accuracy: 0.2371\n",
      "Epoch 8/10\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 2.6203 - accuracy: 0.2371\n",
      "Epoch 9/10\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 2.6189 - accuracy: 0.2371\n",
      "Epoch 10/10\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 2.6176 - accuracy: 0.2371\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 2.6157 - accuracy: 0.2648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.26475605368614197"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(X_train2, y_train2, X_test2, y_test2, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7da2e088",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test2)\n",
    "Y_pred = np.argmax(Y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01b8558",
   "metadata": {},
   "source": [
    "### 7. Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeff643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,ytr)\n",
    "#y_pred_test = gnb.predict(X_test)\n",
    "accuracy = gnb.score(X_test, yte)\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ccab52",
   "metadata": {},
   "source": [
    "### 8. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25a133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(solver = 'saga',multi_class='auto')\n",
    "logreg.fit(X_train,ytr)\n",
    "accuracy = logreg.score(X_test, yte)\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3796ffee",
   "metadata": {},
   "source": [
    "# Analysis of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0441541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yte = np.expand_dims(yte, axis=1)\n",
    "Yte=pd.DataFrame(Yte,columns = ['Emotions'])\n",
    "Y_pred=pd.DataFrame(Y_pred,columns = ['Emotions'])\n",
    "\n",
    "dict = pd.DataFrame({0:'Anger',1:'Sad',2:'Guilt',3:'Shame',4:'Disgust',5:'Anxiety',6:'Fear',7:'Surprise',8:'Contempt',9:'Satisfaction',\n",
    "            10:'WarmHeart.',11:'Happiness',12:'Love',13:'Neutral'}, index=[0])\n",
    "\n",
    "Yte=Yte.replace({\"Emotions\": dict})\n",
    "Y_pred=Y_pred.replace({\"Emotions\": dict})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82c6cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.30      0.73      0.42        60\n",
      "     Anxiety       0.21      0.35      0.26       148\n",
      "    Contempt       0.29      0.28      0.29       240\n",
      "     Disgust       0.34      0.27      0.30       192\n",
      "        Fear       0.20      0.15      0.17       156\n",
      "   Happiness       0.39      0.34      0.36       776\n",
      "        Love       0.18      0.13      0.15       104\n",
      "     Neutral       0.23      0.24      0.23       208\n",
      "         Sad       0.43      0.56      0.49       168\n",
      "Satisfaction       0.19      0.13      0.15       315\n",
      "       Shame       0.19      0.25      0.22       304\n",
      "    Surprise       0.29      0.31      0.30        72\n",
      "  WarmHeart.       0.11      0.10      0.10       188\n",
      "\n",
      "    accuracy                           0.28      2931\n",
      "   macro avg       0.26      0.30      0.27      2931\n",
      "weighted avg       0.28      0.28      0.27      2931\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(Yte, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f2e99d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b8f3db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
