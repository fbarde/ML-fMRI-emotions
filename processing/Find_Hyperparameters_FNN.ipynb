{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General aim of this Notebook :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general aim of this notebook is to find the best hyperparameters for the Fully Connected Neural Network, using GridSearchCV. \n",
    "\n",
    "In order to use it, one needs to load the training datas. \n",
    "\n",
    "The best hyperparameters found are indicated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_path = 'C:/Users/Flore.MININT-64PJ14C/Documents/GitHub/ML_Project2/results/Split_400_0.8/Combined_All_Train_80.csv'\n",
    "tx_train = pd.read_csv(data_train_path,sep=\",\",squeeze=True)\n",
    "X_train=tx_train.iloc[:, :400]\n",
    "ytr = pd.read_csv(data_train_path,sep=\",\",usecols=[400],squeeze=True)\n",
    "y_train = tf.keras.utils.to_categorical(ytr,num_classes=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10747, 400)\n",
      "(10747, 14)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, Dropout, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X_train.shape[0], X_train.shape[1]\n",
    "n_outputs=14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best batch size and number of epoch, BEST: bs=100 and epoch=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # create model\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(8, input_dim=48, activation='relu'))\n",
    "    model.add(Dense(14, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.290430 using {'batch_size': 100, 'epochs': 10}\n",
      "0.212102 (0.039150) with: {'batch_size': 1, 'epochs': 10}\n",
      "0.209001 (0.038168) with: {'batch_size': 1, 'epochs': 50}\n",
      "0.209581 (0.044404) with: {'batch_size': 1, 'epochs': 100}\n",
      "0.262900 (0.056330) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.221120 (0.055011) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.219665 (0.052009) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.269104 (0.057271) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.228678 (0.034826) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.213169 (0.033853) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.285777 (0.054195) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.235370 (0.060106) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.209195 (0.049535) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.270753 (0.061441) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.231198 (0.028733) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.225287 (0.048227) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.281314 (0.025681) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.240605 (0.055729) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.229067 (0.039082) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.290430 (0.051320) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.246616 (0.066654) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.226257 (0.050745) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [1, 10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best optimizer, BEST : Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='Adagrad'):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(8, input_dim=400, activation='relu'))\n",
    "    model.add(Dense(14, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.268169 using {'optimizer': 'SGD'}\n",
      "0.268169 (0.032080) with: {'optimizer': 'SGD'}\n",
      "0.202941 (0.005949) with: {'optimizer': 'RMSprop'}\n",
      "0.164881 (0.100062) with: {'optimizer': 'Adagrad'}\n",
      "0.051366 (0.039467) with: {'optimizer': 'Adadelta'}\n",
      "0.225184 (0.038334) with: {'optimizer': 'Adam'}\n",
      "0.240258 (0.051223) with: {'optimizer': 'Adamax'}\n",
      "0.219695 (0.047227) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "#create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=100, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best learning rate, BEST : 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learn_rate=0.01, momentum=0):\n",
    "    # create model\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(8, input_dim=400, activation='relu'))\n",
    "    model.add(Dense(14, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    optimizer = tf.keras.optimizers.SGD(lr=learn_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.263607 using {'learn_rate': 0.01}\n",
      "0.216058 (0.070653) with: {'learn_rate': 0.001}\n",
      "0.263607 (0.041432) with: {'learn_rate': 0.01}\n",
      "0.207594 (0.009296) with: {'learn_rate': 0.1}\n",
      "0.200431 (0.022596) with: {'learn_rate': 0.2}\n",
      "0.190286 (0.018987) with: {'learn_rate': 0.3}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=100, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "param_grid = dict(learn_rate=learn_rate)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best Network Weight Initialization, BEST: zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(init_mode='uniform'):\n",
    "    # create model\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(8, input_dim=400, activation='relu',kernel_initializer=init_mode))\n",
    "    model.add(Dense(14, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    optimizer = tf.keras.optimizers.SGD(lr=0.01)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.363358 using {'init_mode': 'zero'}\n",
      "0.280730 (0.018028) with: {'init_mode': 'uniform'}\n",
      "0.261189 (0.043770) with: {'init_mode': 'lecun_uniform'}\n",
      "0.264910 (0.047187) with: {'init_mode': 'normal'}\n",
      "0.363358 (0.030625) with: {'init_mode': 'zero'}\n",
      "0.265566 (0.034485) with: {'init_mode': 'glorot_normal'}\n",
      "0.247418 (0.051744) with: {'init_mode': 'glorot_uniform'}\n",
      "0.292453 (0.034368) with: {'init_mode': 'he_normal'}\n",
      "0.259237 (0.026453) with: {'init_mode': 'he_uniform'}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=100, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "param_grid = dict(init_mode=init_mode)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best Neuron Activation Function, BEST: 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(activation='relu'):\n",
    "    # create model\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(6, input_dim=400, activation=activation,kernel_initializer='zero'))\n",
    "    model.add(Dense(14, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    optimizer = tf.keras.optimizers.SGD(lr=0.01)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.363358 using {'activation': 'softmax'}\n",
      "0.363358 (0.030625) with: {'activation': 'softmax'}\n",
      "0.285940 (0.023939) with: {'activation': 'softplus'}\n",
      "0.284454 (0.025876) with: {'activation': 'softsign'}\n",
      "0.363358 (0.030625) with: {'activation': 'relu'}\n",
      "0.261281 (0.023263) with: {'activation': 'tanh'}\n",
      "0.363358 (0.030625) with: {'activation': 'sigmoid'}\n",
      "0.351447 (0.015737) with: {'activation': 'hard_sigmoid'}\n",
      "0.245094 (0.020847) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=100, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best Number of Neurons in the Hidden Layer, BEST: 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(neurons=6):\n",
    "    # create model\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Dense(neurons, input_dim=400, activation='softmax',kernel_initializer='zero'))\n",
    "    model.add(Dense(14, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    optimizer = tf.keras.optimizers.SGD(lr=0.01)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.363358 using {'neurons': 8}\n",
      "0.362893 (0.030754) with: {'neurons': 6}\n",
      "0.363358 (0.030625) with: {'neurons': 8}\n",
      "0.361125 (0.027663) with: {'neurons': 10}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=100, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "neurons = [6, 8, 10]\n",
    "param_grid = dict(neurons=neurons)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
